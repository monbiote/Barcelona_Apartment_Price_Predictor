{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_test = pd.read_csv('test.csv')\\ndf_test.head()\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_train.head()\n",
    "\n",
    "'''\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_test.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id    num_rooms    num_baths  square_meters   year_built  \\\n",
      "count   8000.000000  8000.000000  7840.000000    7845.000000  7830.000000   \n",
      "mean    5012.506875     2.868500     1.988265     108.031995  1985.321073   \n",
      "std     2887.649416     5.300469     0.815943      38.671420    20.591437   \n",
      "min        2.000000     1.000000     1.000000    -100.000000  1950.000000   \n",
      "25%     2512.750000     1.000000     1.000000      78.000000  1968.000000   \n",
      "50%     5014.500000     2.000000     2.000000     110.000000  1985.000000   \n",
      "75%     7505.250000     4.000000     3.000000     140.000000  2003.000000   \n",
      "max    10000.000000    97.000000     3.000000     170.000000  2021.000000   \n",
      "\n",
      "        num_crimes  num_supermarkets        price  \n",
      "count  7840.000000       1411.000000  8000.000000  \n",
      "mean      2.803444          1.982991  1099.616250  \n",
      "std       3.447714          0.803182   271.686617  \n",
      "min       0.000000          1.000000   195.000000  \n",
      "25%       0.000000          1.000000   905.750000  \n",
      "50%       1.000000          2.000000  1104.000000  \n",
      "75%       6.000000          3.000000  1295.000000  \n",
      "max      10.000000          3.000000  2095.000000  \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NUM_ROOMS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/guillemmirabentrubinat/Library/CloudStorage/OneDrive-Personal/BSE/CML Computational Machine Learning/Apartment Prices/Group_5_Sarria/Sarria.ipynb Cell 2\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guillemmirabentrubinat/Library/CloudStorage/OneDrive-Personal/BSE/CML%20Computational%20Machine%20Learning/Apartment%20Prices/Group_5_Sarria/Sarria.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Start the exploration\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guillemmirabentrubinat/Library/CloudStorage/OneDrive-Personal/BSE/CML%20Computational%20Machine%20Learning/Apartment%20Prices/Group_5_Sarria/Sarria.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(df_train\u001b[39m.\u001b[39mdescribe())\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guillemmirabentrubinat/Library/CloudStorage/OneDrive-Personal/BSE/CML%20Computational%20Machine%20Learning/Apartment%20Prices/Group_5_Sarria/Sarria.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m NUM_ROOMS\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guillemmirabentrubinat/Library/CloudStorage/OneDrive-Personal/BSE/CML%20Computational%20Machine%20Learning/Apartment%20Prices/Group_5_Sarria/Sarria.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m outliers \u001b[39m=\u001b[39m df_train[df_train[\u001b[39m'\u001b[39m\u001b[39mnum_rooms\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m6\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guillemmirabentrubinat/Library/CloudStorage/OneDrive-Personal/BSE/CML%20Computational%20Machine%20Learning/Apartment%20Prices/Group_5_Sarria/Sarria.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(outliers)) \u001b[39m# too many outliers, propose mean imputation per neighborhood\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NUM_ROOMS' is not defined"
     ]
    }
   ],
   "source": [
    "# Start the exploration\n",
    "\n",
    "print(df_train.describe())\n",
    "\n",
    "# INVESTIGATE WHETHER THE MISSING VALUES ARE AT RANDOM OR NOT\n",
    "\n",
    "# NUM_ROOMS\n",
    "outliers = df_train[df_train['num_rooms'] > 6]\n",
    "print(len(outliers)) # too many outliers, propose mean imputation per neighborhood\n",
    "\n",
    "\n",
    "\n",
    "# filling outliers\n",
    "# distr_means = df_train[df_train['neighborhood']].mean()\n",
    "# distr_means.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR BOOLEANS, REMOVE REFERS TO PAIRWISE DELETION\n",
    "\n",
    "NUM_BATHROOMS treat identically to num_rooms\n",
    "\n",
    "SQUARE_METERS a lot of negatives\n",
    "treat it 3 different ways, 1) remove negatives (just leave values as positives) and then treat outliers with mean imputation, 2) replace with mean per neighborhood, 3) Logical approach\n",
    "\n",
    "ORIENTATION only relevant in relation to the neighborhood and above a certain floor if it's facing the sea (treat as secondary)\n",
    "\n",
    "FLOOR treat missing values (by neighborhood)\n",
    "\n",
    "DOOR the actual door not important but extracting the floor is important\n",
    "\n",
    "FURNISHED boolean value (secondary), MISSING VALUES REMOVE\n",
    "\n",
    "HAS POOL boolean value (secondary), MISSING VALUES REMOVE, analyze the effect by neighborhood\n",
    "\n",
    "NEIGHBORHOOD categorical variable, MISSING VALUES REMOVE, check (secondary check)\n",
    "\n",
    "NUM_CRIMES ANALYZE PER NEIGHBORHOOD, NEIGHBORHOODS TOO WIDE TREAT CAREFULLY\n",
    "\n",
    "HAS_AC boolean value, MISSING VALUES REMOVE\n",
    "\n",
    "ACCEPTS_PETS boolean value, MISSING VALUES REMOVE\n",
    "\n",
    "NUM_SUPERMARKETS too many missing, JUST REMOVE COLUMN\n",
    "\n",
    "num_rooms, outliers in > 6, propose removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'apartment_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\monbi\\Downloads\\Sarria.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/monbi/Downloads/Sarria.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m mean_squared_error\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/monbi/Downloads/Sarria.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Load your dataset\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/monbi/Downloads/Sarria.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mapartment_data.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/monbi/Downloads/Sarria.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# Split the data into features (X) and target (y)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/monbi/Downloads/Sarria.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m X \u001b[39m=\u001b[39m data[[\u001b[39m'\u001b[39m\u001b[39mneighborhood\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnum_rooms\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mnum_baths\u001b[39m\u001b[39m'\u001b[39m]]\n",
      "File \u001b[1;32mc:\\Users\\monbi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\monbi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\monbi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\monbi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\monbi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'apartment_data.csv'"
     ]
    }
   ],
   "source": [
    "#Ed draft model code\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split  #split data into training and testing sets\n",
    "from sklearn.linear_model import LinearRegression #create linear regression model\n",
    "from sklearn.metrics import mean_squared_error #evaluate the model performance\n",
    "\n",
    "#Part 1: create model\n",
    "\n",
    "# Load the train dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data[['neighborhood', 'num_rooms', 'num_baths']] #we need to select the key feature columns \n",
    "y = data['price'] #what we want to predict\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a linear regression model\n",
    "model = LinearRegression() #LR model created and initialised\n",
    "model.fit(X_train, y_train) #trained on the training data using the .fit() function\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test) #via the trained model\n",
    "\n",
    "#Part 2: Check Model\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred) #measure model performance, lower the MSE the better the fit between the predicted and the actual prices.  \n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "#Part 3 Predict and add apartment prices in the test dataset\n",
    "\n",
    "# Use trained model to predict prices for apartments in the test dataset\n",
    "test_data = pd.read_csv('test.csv')  # Load your test dataset\n",
    "predicted_prices = model.predict(test_data[['neighborhood', 'num_rooms', 'num_baths']])\n",
    "\n",
    "# Add the predicted prices to the test dataset\n",
    "test_data['predicted_price'] = predicted_prices\n",
    "\n",
    "# Save the test dataset with predicted prices to a new CSV file\n",
    "test_data.to_csv('predicted_apartment_prices.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL RELATED NOTES\n",
    "\n",
    "Try lasso, ridge and linear model, BEGIN WITH LINEAR"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
